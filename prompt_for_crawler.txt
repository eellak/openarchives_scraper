Read and understand the data in /mnt/data/openarchive_scraper/openarchives_results/edm_metadata_labeled.parquet
/mnt/data/openarchive_scraper/openarchives_results/collections_links_enriched_ge1k_sorted.parquet

learn the columns etc and what they contain.

The two parquets are related this way:

one contains all pdfs links scraped by openarchives.gr
the other contains all the collections that have some greek text or "none" texts i.e. that language of pdf is not indicated AND also more than 1000 "items" i.e. pdfs.

what we want to do is make a crawler that make requests to all external links of pdfs that are in these collections AND are ELL or NONE in language.

We want the crawler to be extremely efficient with fetching the contents from the external link. The crawler should fetch all pdfs links found in the external link, and should store them in the order they appear from top to bottom in a list.

You should model the crawler on previous succesful scrapers e.g. /mnt/data/openarchive_scraper/scraper/fast_scraper/fetch_edm_metadata.py 